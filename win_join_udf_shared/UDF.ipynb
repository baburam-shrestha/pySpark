{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86fda012",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F \n",
    "from pyspark.sql import Window\n",
    "import pyspark.sql.types as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7ed8c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/19 11:43:08 WARN Utils: Your hostname, HP-G62 resolves to a loopback address: 127.0.1.1; using 192.168.18.113 instead (on interface enp3s0)\n",
      "22/10/19 11:43:08 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/19 11:43:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/10/19 11:43:11 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/10/19 11:43:11 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "22/10/19 11:43:11 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "22/10/19 11:43:11 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "22/10/19 11:43:11 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n",
      "22/10/19 11:43:11 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.\n",
      "22/10/19 11:43:11 WARN Utils: Service 'SparkUI' could not bind on port 4046. Attempting port 4047.\n",
      "22/10/19 11:43:11 WARN Utils: Service 'SparkUI' could not bind on port 4047. Attempting port 4048.\n",
      "22/10/19 11:43:11 WARN Utils: Service 'SparkUI' could not bind on port 4048. Attempting port 4049.\n"
     ]
    }
   ],
   "source": [
    "spark=SparkSession.builder.appName(\"UDF: User Defined Functions\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3c5e5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+-------------+\n",
      "|FIRST_NAME|SALARY|DEPARTMENT_ID|\n",
      "+----------+------+-------------+\n",
      "|    Donald|  2600|           50|\n",
      "|   Douglas|  2600|           50|\n",
      "|  Jennifer|  4400|           10|\n",
      "|   Michael| 13000|           20|\n",
      "|       Pat|  6000|           20|\n",
      "|     Susan|  6500|           40|\n",
      "|   Hermann| 10000|           70|\n",
      "|   Shelley| 12008|          110|\n",
      "|   William|  8300|          110|\n",
      "|    Steven| 24000|           90|\n",
      "|     Neena| 17000|           90|\n",
      "|       Lex| 17000|           90|\n",
      "| Alexander|  9000|           60|\n",
      "|     Bruce|  6000|           60|\n",
      "|     David|  4800|           60|\n",
      "|     Valli|  4800|           60|\n",
      "|     Diana|  4200|           60|\n",
      "|     Nancy| 12008|          100|\n",
      "|    Daniel|  9000|          100|\n",
      "|      John|  8200|          100|\n",
      "+----------+------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee_df=spark.read.csv(\"employees.csv\",inferSchema=True,header=True)\n",
    "employee_df= employee_df.select([\"FIRST_NAME\",\"SALARY\",\"DEPARTMENT_ID\"])\n",
    "employee_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c6a511e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1000.0, 100.0, 8900.0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def salary_details(salary):\n",
    "    basic_salary=salary\n",
    "    ssf=0.1*basic_salary\n",
    "    tax=0.01*basic_salary\n",
    "    net_salary=basic_salary-ssf-tax\n",
    "    return [ssf,tax,net_salary,]\n",
    "\n",
    "salary_details(10000)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e0e8c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to register the function to make it available as a DataFrame function:\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "salary_details_udf = udf(salary_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23596703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|SSF, Tax, Net Salary|\n",
      "+--------------------+\n",
      "|[260.0, 26.0, 231...|\n",
      "|[260.0, 26.0, 231...|\n",
      "|[440.0, 44.0, 391...|\n",
      "|[1300.0, 130.0, 1...|\n",
      "|[600.0, 60.0, 534...|\n",
      "|[650.0, 65.0, 578...|\n",
      "|[1000.0, 100.0, 8...|\n",
      "|[1200.8, 120.08, ...|\n",
      "|[830.0, 83.0, 738...|\n",
      "|[2400.0, 240.0, 2...|\n",
      "|[1700.0, 170.0, 1...|\n",
      "|[1700.0, 170.0, 1...|\n",
      "|[900.0, 90.0, 801...|\n",
      "|[600.0, 60.0, 534...|\n",
      "|[480.0, 48.0, 427...|\n",
      "|[480.0, 48.0, 427...|\n",
      "|[420.0, 42.0, 373...|\n",
      "|[1200.8, 120.08, ...|\n",
      "|[900.0, 90.0, 801...|\n",
      "|[820.0, 82.0, 729...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Then, we can use it in our DataFrame code:\n",
    "from pyspark.sql.functions import col\n",
    "employee_df.select(salary_details_udf(col(\"SALARY\")).alias(\"SSF, Tax, Net Salary\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f60db6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+--------+------------+---------+----------+------+--------------+----------+-------------+\n",
      "|EMPLOYEE_ID|FIRST_NAME|LAST_NAME|   EMAIL|PHONE_NUMBER|HIRE_DATE|    JOB_ID|SALARY|COMMISSION_PCT|MANAGER_ID|DEPARTMENT_ID|\n",
      "+-----------+----------+---------+--------+------------+---------+----------+------+--------------+----------+-------------+\n",
      "|        198|    Donald| OConnell|DOCONNEL|650.507.9833|21-JUN-07|  SH_CLERK|  2600|            - |       124|           50|\n",
      "|        199|   Douglas|    Grant|  DGRANT|650.507.9844|13-JAN-08|  SH_CLERK|  2600|            - |       124|           50|\n",
      "|        200|  Jennifer|   Whalen| JWHALEN|515.123.4444|17-SEP-03|   AD_ASST|  4400|            - |       101|           10|\n",
      "|        201|   Michael|Hartstein|MHARTSTE|515.123.5555|17-FEB-04|    MK_MAN| 13000|            - |       100|           20|\n",
      "|        202|       Pat|      Fay|    PFAY|603.123.6666|17-AUG-05|    MK_REP|  6000|            - |       201|           20|\n",
      "|        203|     Susan|   Mavris| SMAVRIS|515.123.7777|07-JUN-02|    HR_REP|  6500|            - |       101|           40|\n",
      "|        204|   Hermann|     Baer|   HBAER|515.123.8888|07-JUN-02|    PR_REP| 10000|            - |       101|           70|\n",
      "|        205|   Shelley|  Higgins|SHIGGINS|515.123.8080|07-JUN-02|    AC_MGR| 12008|            - |       101|          110|\n",
      "|        206|   William|    Gietz|  WGIETZ|515.123.8181|07-JUN-02|AC_ACCOUNT|  8300|            - |       205|          110|\n",
      "|        100|    Steven|     King|   SKING|515.123.4567|17-JUN-03|   AD_PRES| 24000|            - |        - |           90|\n",
      "|        101|     Neena|  Kochhar|NKOCHHAR|515.123.4568|21-SEP-05|     AD_VP| 17000|            - |       100|           90|\n",
      "|        102|       Lex|  De Haan| LDEHAAN|515.123.4569|13-JAN-01|     AD_VP| 17000|            - |       100|           90|\n",
      "|        103| Alexander|   Hunold| AHUNOLD|590.423.4567|03-JAN-06|   IT_PROG|  9000|            - |       102|           60|\n",
      "|        104|     Bruce|    Ernst|  BERNST|590.423.4568|21-MAY-07|   IT_PROG|  6000|            - |       103|           60|\n",
      "|        105|     David|   Austin| DAUSTIN|590.423.4569|25-JUN-05|   IT_PROG|  4800|            - |       103|           60|\n",
      "|        106|     Valli|Pataballa|VPATABAL|590.423.4560|05-FEB-06|   IT_PROG|  4800|            - |       103|           60|\n",
      "|        107|     Diana|  Lorentz|DLORENTZ|590.423.5567|07-FEB-07|   IT_PROG|  4200|            - |       103|           60|\n",
      "|        108|     Nancy|Greenberg|NGREENBE|515.124.4569|17-AUG-02|    FI_MGR| 12008|            - |       101|          100|\n",
      "|        109|    Daniel|   Faviet| DFAVIET|515.124.4169|16-AUG-02|FI_ACCOUNT|  9000|            - |       108|          100|\n",
      "|        110|      John|     Chen|   JCHEN|515.124.4269|28-SEP-05|FI_ACCOUNT|  8200|            - |       108|          100|\n",
      "+-----------+----------+---------+--------+------------+---------+----------+------+--------------+----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee_df=spark.read.csv(\"employees.csv\",inferSchema=True,header=True)\n",
    "employee_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4b4783ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def email(emal):\n",
    "    return emal.lower()+\"@hotmail.com\"\n",
    "def phone(phon):\n",
    "    phon=str(phon).split(\".\")\n",
    "    return \"+977-\"+phon[0]+\"-\"+ phon[1]+\"-\"+phon[2]\n",
    "\n",
    "def name(flname):\n",
    "    naame=flname.title()\n",
    "    return naame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5f2f67c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to register the function to make it available as a DataFrame function:\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "email_udf = udf(email)\n",
    "phone_udf = udf(phone)\n",
    "name_udf=udf(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d09285f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|              E mail|\n",
      "+--------------------+\n",
      "|doconnel@hotmail.com|\n",
      "|  dgrant@hotmail.com|\n",
      "| jwhalen@hotmail.com|\n",
      "|mhartste@hotmail.com|\n",
      "|    pfay@hotmail.com|\n",
      "| smavris@hotmail.com|\n",
      "|   hbaer@hotmail.com|\n",
      "|shiggins@hotmail.com|\n",
      "|  wgietz@hotmail.com|\n",
      "|   sking@hotmail.com|\n",
      "|nkochhar@hotmail.com|\n",
      "| ldehaan@hotmail.com|\n",
      "| ahunold@hotmail.com|\n",
      "|  bernst@hotmail.com|\n",
      "| daustin@hotmail.com|\n",
      "|vpatabal@hotmail.com|\n",
      "|dlorentz@hotmail.com|\n",
      "|ngreenbe@hotmail.com|\n",
      "| dfaviet@hotmail.com|\n",
      "|   jchen@hotmail.com|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Then, we can use it in our DataFrame code:\n",
    "from pyspark.sql.functions import col\n",
    "employee_df.select(email_udf(col(\"EMAIL\")).alias(\"E mail\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "acae87a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|     Phone NUmber|\n",
      "+-----------------+\n",
      "|+977-650-507-9833|\n",
      "|+977-650-507-9844|\n",
      "|+977-515-123-4444|\n",
      "|+977-515-123-5555|\n",
      "|+977-603-123-6666|\n",
      "|+977-515-123-7777|\n",
      "|+977-515-123-8888|\n",
      "|+977-515-123-8080|\n",
      "|+977-515-123-8181|\n",
      "|+977-515-123-4567|\n",
      "|+977-515-123-4568|\n",
      "|+977-515-123-4569|\n",
      "|+977-590-423-4567|\n",
      "|+977-590-423-4568|\n",
      "|+977-590-423-4569|\n",
      "|+977-590-423-4560|\n",
      "|+977-590-423-5567|\n",
      "|+977-515-124-4569|\n",
      "|+977-515-124-4169|\n",
      "|+977-515-124-4269|\n",
      "+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee_df.select(phone_udf(col(\"PHONE_NUMBER\")).alias(\"Phone NUmber\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f13f51fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname=employee_df.select(name_udf(col(\"FIRST_NAME\")).alias(\"First Name\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cf052a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lname=employee_df.select(name_udf(col(\"LAST_NAME\")).alias(\"Last Name\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "66323bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[First Name: string]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7016c91b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "type(lname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fd80a8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|First Name|Last Name|\n",
      "+----------+---------+\n",
      "|    Donald| Oconnell|\n",
      "|    Donald|    Grant|\n",
      "|    Donald|   Whalen|\n",
      "|    Donald|Hartstein|\n",
      "|    Donald|      Fay|\n",
      "|    Donald|   Mavris|\n",
      "|    Donald|     Baer|\n",
      "|    Donald|  Higgins|\n",
      "|    Donald|    Gietz|\n",
      "|    Donald|     King|\n",
      "|    Donald|  Kochhar|\n",
      "|    Donald|  De Haan|\n",
      "|    Donald|   Hunold|\n",
      "|    Donald|    Ernst|\n",
      "|    Donald|   Austin|\n",
      "|    Donald|Pataballa|\n",
      "|    Donald|  Lorentz|\n",
      "|    Donald|Greenberg|\n",
      "|    Donald|   Faviet|\n",
      "|    Donald|     Chen|\n",
      "+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fullname=fname.join(lname)\n",
    "fullname.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
