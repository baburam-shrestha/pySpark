{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec0e7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark caching can be used to pull data sets into a cluster-wide in-memory cahche.\n",
    "# This is very useful for accessing repeated data, such as querying a small \"hot\" dataset or when running an iterative algorithm\n",
    "# there are two ways to persist RDDs in spark\n",
    "#     cache()\n",
    "#     persist()\n",
    "\n",
    "# there are some advantages of RDD caching and persistance mechanism in spark\n",
    "#     time efficient\n",
    "#     cost efficient\n",
    "#     lessen the execution time\n",
    "    \n",
    "# STORAGE TYPEs:\n",
    "#     MEMORY_ONLY\n",
    "#     MEMORY_AND_DISK\n",
    "#     MEMORY_ONLY_SER\n",
    "#     MEMOTY_AND_DISK_SER\n",
    "#     DISK_ONLY\n",
    "#     OFF_HEAP\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba24536f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdd unpersist\n",
    "\n",
    "# spark automatically monitors cache usage on each node and drops our old data \n",
    "# partition in a least_recently-used(LRU) fashion\n",
    "\n",
    "# If you would like to manually remove an RDD instead of waiting for it to fall out os the cache,\n",
    "# use the RDD.unpersist() method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd1ff568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the spark context\n",
    "from pyspark import SparkContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea38a406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/31 09:39:16 WARN Utils: Your hostname, HP-G62 resolves to a loopback address: 127.0.1.1; using 192.168.18.113 instead (on interface enp3s0)\n",
      "22/10/31 09:39:16 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/31 09:39:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.18.113:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=pyspark-shell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create SparkContext\n",
    "sc=SparkContext.getOrCreate()\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e576c757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Company,Person,Sales',\n",
       " 'GOOG,Sam,200',\n",
       " 'GOOG,Charlie,120',\n",
       " 'GOOG,Frank,340',\n",
       " 'MSFT,Tina,600',\n",
       " 'MSFT,Amy,124',\n",
       " 'MSFT,Vanessa,243',\n",
       " 'FB,Carl,870',\n",
       " 'FB,Sarah,350',\n",
       " 'APPL,John,250',\n",
       " 'APPL,Linda, 130',\n",
       " 'APPL,Mike, 750',\n",
       " 'APPL, Chris, 350']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_rdd=sc.textFile(\"sales.csv\")\n",
    "sales_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ea930e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sales_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70d3c8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9322425360001034"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting total time taken for the count before cache enabled/\n",
    "import timeit as t\n",
    "start=t.default_timer()\n",
    "sales_rdd.count()\n",
    "sales_rdd.min()\n",
    "sales_rdd.max()\n",
    "sales_rdd.collect()\n",
    "end=t.default_timer()\n",
    "time_elapsed=(end-start)\n",
    "time_elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be2ce43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sales.csv MapPartitionsRDD[13] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_rdd.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b64cc1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9199051570003576"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting total time taken for the count after cache enabled/\n",
    "import timeit as t\n",
    "start=t.default_timer()\n",
    "sales_rdd.count()\n",
    "sales_rdd.min()\n",
    "sales_rdd.max()\n",
    "sales_rdd.collect()\n",
    "end=t.default_timer()\n",
    "time_elapsed=(end-start)\n",
    "time_elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bacae47c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sales.csv MapPartitionsRDD[13] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unpersist the data from the momory\n",
    "sales_rdd.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3acba8bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5988162250000642"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting total time taken for the count after unpersistance\n",
    "import timeit as t\n",
    "start=t.default_timer()\n",
    "sales_rdd.count()\n",
    "sales_rdd.min()\n",
    "sales_rdd.max()\n",
    "sales_rdd.collect()\n",
    "end=t.default_timer()\n",
    "time_elapsed=(end-start)\n",
    "time_elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a9a71a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading pyspark for cache() and persist()\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "98f38605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sales.csv MapPartitionsRDD[13] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#caching the data in memory\n",
    "sales_rdd.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bfc486de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sales.csv MapPartitionsRDD[13] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unpersisting the data from memory\n",
    "sales_rdd.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "59ccde26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sales.csv MapPartitionsRDD[13] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# persisting teh data in disk\n",
    "sales_rdd.persist(pyspark.StorageLevel.DISK_ONLY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fbb6229a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sales.csv MapPartitionsRDD[13] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unpersisting the data from memory\n",
    "sales_rdd.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "62328f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Company,Person,Sales',\n",
       " 'GOOG,Sam,200',\n",
       " 'GOOG,Charlie,120',\n",
       " 'GOOG,Frank,340',\n",
       " 'MSFT,Tina,600',\n",
       " 'MSFT,Amy,124',\n",
       " 'MSFT,Vanessa,243',\n",
       " 'FB,Carl,870',\n",
       " 'FB,Sarah,350',\n",
       " 'APPL,John,250']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_rdd.take(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
